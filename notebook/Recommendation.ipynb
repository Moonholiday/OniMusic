{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d2320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 15/126 [12:28<1:32:30, 50.00s/it]"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "# Import modules\n",
    "import sys\n",
    "# If your authentification script is not in the project directory\n",
    "# append its folder to sys.path\n",
    "sys.path.append(\"../spotify_api_web_app\")\n",
    "import authorization\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Authorize and call access object \"sp\"\n",
    "sp = authorization.authorize()\n",
    "\n",
    "# Get all genres\n",
    "genres = sp.recommendation_genre_seeds()\n",
    "\n",
    "# Set number of recommendations per genre\n",
    "n_recs = 100\n",
    "\n",
    "# Initiate a dictionary with all the information you want to crawl\n",
    "data_dict = {\"id\":[], \"genre\":[], \"track_name\":[], \"artist_name\":[],\n",
    "             \"valence\":[], \"energy\":[]}\n",
    "\n",
    "################\n",
    "## CRAWL DATA ##\n",
    "################\n",
    "\n",
    "# Get recs for every genre\n",
    "for g in tqdm(genres):\n",
    "    \n",
    "    # Get n recommendations\n",
    "    recs = sp.recommendations(genres = [g], limit = n_recs)\n",
    "    # json-like string to dict\n",
    "    recs = eval(recs.json().replace(\"null\", \"-999\").replace(\"false\", \"False\").replace(\"true\", \"True\"))[\"tracks\"]\n",
    "    \n",
    "    # Crawl data from each track\n",
    "    for track in recs:\n",
    "        # ID and Genre\n",
    "        data_dict[\"id\"].append(track[\"id\"])\n",
    "        data_dict[\"genre\"].append(g)\n",
    "        # Metadata\n",
    "        track_meta = sp.track(track[\"id\"])\n",
    "        data_dict[\"track_name\"].append(track_meta.name)\n",
    "        data_dict[\"artist_name\"].append(track_meta.album.artists[0].name)\n",
    "        # Valence and energy\n",
    "        track_features = sp.track_audio_features(track[\"id\"])\n",
    "        data_dict[\"valence\"].append(track_features.valence)\n",
    "        data_dict[\"energy\"].append(track_features.energy)\n",
    "        \n",
    "        # Wait 0.2 seconds per track so that the api doesnt overheat\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "##################\n",
    "## PROCESS DATA ##\n",
    "##################\n",
    "\n",
    "# Store data in dataframe\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(subset = \"id\", keep = \"first\", inplace = True)\n",
    "df.to_csv(\"valence_arousal_dataset.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(p1, p2):\n",
    "    distance_x = p2[0]-p1[0]\n",
    "    distance_y = p2[1]-p1[1]\n",
    "    distance_vec = [distance_x, distance_y]\n",
    "    norm = (distance_vec[0]**2 + distance_vec[1]**2)**(1/2)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4642aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import authorization # this is the script we created earlier\n",
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"valence_arousal_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mood_vec\"] = df[[\"valence\", \"energy\"]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = authorization.authorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(track_id, ref_df, sp, n_recs = 5):\n",
    "    \n",
    "    # Crawl valence and arousal of given track from spotify api\n",
    "    track_features = sp.track_audio_features(track_id)\n",
    "    track_moodvec = np.array([track_features.valence, track_features.energy])\n",
    "    \n",
    "    # Compute distances to all reference tracks\n",
    "    ref_df[\"distances\"] = ref_df[\"mood_vec\"].apply(lambda x: norm(track_moodvec-np.array(x)))\n",
    "    # Sort distances from lowest to highest\n",
    "    ref_df_sorted = ref_df.sort_values(by = \"distances\", ascending = True)\n",
    "    # If the input track is in the reference set, it will have a distance of 0, but should not be recommendet\n",
    "    ref_df_sorted = ref_df_sorted[ref_df_sorted[\"id\"] != track_id]\n",
    "    \n",
    "    # Return n recommendations\n",
    "    return ref_df_sorted.iloc[:n_recs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86163601",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake = \"5hVghJ4KaYES3BFUATCYn0\"\n",
    "recommend(track_id = mad_world, ref_df = df, sp = sp, n_recs = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
